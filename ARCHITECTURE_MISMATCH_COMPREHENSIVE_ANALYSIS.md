# Comprehensive Architecture Mismatch Analysis

## Executive Summary Paragraph

The architecture diagnostic revealed a fundamental and critical mismatch between the trained model checkpoint and the current inference code that completely explains why the Modified StreamSpeech mode generates static buzz with no vertical variations in the mel-spectrogram. **The diagnostic shows that the checkpoint contains only 94 parameters representing a simplified GRC (Grouped Residual Convolution) structure where each of the 5 MRF (Multi-Receptive Field Fusion) layers contains 3 GRC blocks (labeled `convs.0`, `convs.1`, and `convs.2`), with each GRC block having exactly 4 parameters: `conv1.weight`, `conv1.bias`, `conv2.weight`, and `conv2.bias`, using full-channel convolutions with shapes like `[512, 512, 3]`, `[256, 256, 5]`, and `[128, 128, 7]` that indicate no channel grouping and varying kernel sizes (3, 5, 7) to create multi-receptive field patterns.** In stark contrast, the current inference code in `grc_lora.py` creates a vastly more complex `GroupedResidualConvolution` class that generates 24 parameters per GRC block (6 times more than the checkpoint), including not only `conv1` and `conv2` but also `norm1.weight`, `norm1.bias`, `norm1.running_mean`, `norm1.running_var`, `norm2.weight`, `norm2.bias`, `norm2.running_mean`, `norm2.running_var`, `lora_conv1.lora_A`, `lora_conv1.lora_B`, `lora_conv2.lora_A`, `lora_conv2.lora_B`, `channel_attention.1.weight`, `channel_attention.1.bias`, `channel_attention.3.weight`, `channel_attention.3.bias`, `temporal_attention.0.weight`, and `temporal_attention.0.bias`, totaling 394 parameters across the entire model compared to the checkpoint's 94. **Furthermore, the current code uses grouped convolutions (groups=4) producing shapes like `[512, 128, 3]` instead of the checkpoint's full-channel convolutions with shapes like `[512, 512, 3]`, and incorrectly varies kernel sizes through dilation (kernel_size=3 with dilation=1,3,5 in the code) instead of through actual kernel size changes (kernel_size=3,5,7 in the checkpoint), creating a double mismatch in both channel connectivity and receptive field implementation.** The diagnostic output explicitly shows "Keys in model but not checkpoint: 300" and lists all the attention, LoRA, and normalization parameters that exist in the current code but were never trained, meaning these 300 parameters have completely random, uninitialized weights. **When PyTorch's `load_state_dict()` encounters this mismatch, the 94 checkpoint parameters that do match the model's `conv1` and `conv2` parameters attempt to load, but their shapes don't align due to the grouped convolution issue (`[512, 512, 3]` cannot load into `[512, 128, 3]`), resulting in shape mismatch errors like "Checkpoint: [512, 512, 3], Model: [512, 128, 3]" repeated across 30 different parameters, so even the parameters that have matching names fail to load due to incompatible dimensions.** The consequence is catastrophic: the vocoder runs with entirely random weights across all its convolutional layers, and when a neural network vocoder with untrained weights attempts to convert mel-spectrograms to audio, it produces white noise because the random convolution kernels cannot reconstruct the complex harmonic structure of speech from spectral features, instead outputting uniform random values across all frequency bands at all time steps, which manifests as the perfectly flat horizontal lines observed in the mel-spectrogram visualization (where all 80 mel-frequency bins show identical uniform values with no vertical variation) and audibly as the static buzzing sound. This is fundamentally different from the earlier chipmunk sound issue, which occurred when properly processed audio was merely played at an incorrect sample rate (a post-processing problem), whereas the current static buzz originates from the vocoder itself generating noise rather than speech (a model initialization problem), with the mel-spectrogram comparison providing incontrovertible visual evidence: the input Spanish audio shows clear speech patterns with vertical frequency variations, the Original StreamSpeech output shows similar vertical speech patterns in English, but the Modified mode output shows completely flat horizontal lines across all frequencies, proving that the vocoder is not performing speech synthesis at all but rather outputting white noise due to operating with random uninitialized weights caused by the architecture mismatch preventing any trained weights from loading correctly.

---

## Detailed Code-Level Analysis

### The Checkpoint Structure (What Was Actually Trained)

From the diagnostic output, lines 541-643 show the checkpoint structure:

```
mrfs.0:
  Keys: 12
  Has nested 'convs': True
  Has conv1/conv2: True
  Number of GRC blocks (convs): 3
    convs.0: 4 params
      convs.0.conv1.bias......................                [512]
      convs.0.conv1.weight....................        [512, 512, 3]
      convs.0.conv2.bias......................                [512]
      convs.0.conv2.weight....................        [512, 512, 3]
    convs.1: 4 params
      convs.1.conv1.bias......................                [512]
      convs.1.conv1.weight....................        [512, 512, 5]  ‚Üê kernel=5
      convs.1.conv2.bias......................                [512]
      convs.1.conv2.weight....................        [512, 512, 5]
    convs.2: 4 params
      convs.2.conv1.bias......................                [512]
      convs.2.conv1.weight....................        [512, 512, 7]  ‚Üê kernel=7
      convs.2.conv2.bias......................                [512]
      convs.2.conv2.weight....................        [512, 512, 7]
```

**Key observations:**
1. Each GRC block has **exactly 4 parameters**: conv1.weight, conv1.bias, conv2.weight, conv2.bias
2. Convolution shapes are **full-channel**: `[512, 512, k]` means 512 input channels ‚Üí 512 output channels with no grouping
3. Kernel sizes **vary**: k=3 for convs.0, k=5 for convs.1, k=7 for convs.2
4. **No normalization, no LoRA, no attention mechanisms**

This represents a simple residual block structure:
```python
# What the checkpoint expects (simplified pseudocode)
class SimpleGRCBlock:
    conv1: [channels, channels, kernel_size]
    conv2: [channels, channels, kernel_size]
    
    forward(x):
        return conv2(relu(conv1(x))) + x
```

### The Current Model Structure (What Code Creates)

From the diagnostic output, lines 672-790 show the current model structure:

```
mrfs.0:
  Keys: 72
  Has nested 'convs': True
  Has conv1/conv2: True
  Number of GRC blocks (convs): 3
    convs.0: 24 params  ‚Üê 6x more than checkpoint!
      convs.0.channel_attention.1.bias........                [128]
      convs.0.channel_attention.1.weight......        [128, 512, 1]
      convs.0.channel_attention.3.bias........                [512]
      convs.0.channel_attention.3.weight......        [512, 128, 1]
      ... and 20 more  ‚Üê Attention, LoRA, normalization layers
```

**Key observations:**
1. Each GRC block has **24 parameters** (6x more than checkpoint!)
2. Includes: conv1, conv2, norm1, norm2, lora_conv1, lora_conv2, channel_attention, temporal_attention
3. Uses **grouped convolutions**: `[256, 64, 3]` means 256 channels with groups=4 (256/64=4)
4. All blocks use **kernel_size=3** with varying dilations instead of varying kernel sizes

This is created by the complex `GroupedResidualConvolution` class in `grc_lora.py`:
```python
# Current implementation in grc_lora.py (lines 56-150)
class GroupedResidualConvolution(nn.Module):
    def __init__(self, channels, kernel_size=3, dilation=1, groups=4, lora_rank=4):
        super().__init__()
        
        self.groups = max(1, min(groups, channels))  # groups=4
        
        # Grouped convolutions (NOT full-channel!)
        self.conv1 = nn.Conv1d(channels, channels, kernel_size, 
                              padding=(kernel_size-1)//2, 
                              dilation=dilation, 
                              groups=self.groups)  # ‚Üê Creates [channels, channels/groups, k]
        
        self.conv2 = nn.Conv1d(channels, channels, kernel_size, 
                              padding=(kernel_size-1)//2, 
                              dilation=dilation, 
                              groups=self.groups)
        
        # Batch normalization (NOT in checkpoint!)
        self.norm1 = nn.BatchNorm1d(channels)
        self.norm2 = nn.BatchNorm1d(channels)
        
        # LoRA adaptation (NOT in checkpoint!)
        self.lora_conv1 = LoRALinear(channels, channels, rank=lora_rank)
        self.lora_conv2 = LoRALinear(channels, channels, rank=lora_rank)
        
        # Channel attention (NOT in checkpoint!)
        self.channel_attention = nn.Sequential(
            nn.Conv1d(channels, channels // 4, 1),
            nn.ReLU(),
            nn.Conv1d(channels // 4, channels, 1),
            nn.Sigmoid()
        )
        
        # Temporal attention (NOT in checkpoint!)
        self.temporal_attention = nn.Sequential(
            nn.Conv1d(1, 1, kernel_size, padding=(kernel_size-1)//2),
            nn.Sigmoid()
        )
```

### The Mismatch Breakdown

#### Issue 1: Extra Components (300 Parameters)
**Checkpoint has:** conv1, conv2 only (4 params per block)
**Model creates:** conv1, conv2, norm1, norm2, lora_conv1, lora_conv2, channel_attention, temporal_attention (24 params per block)

**Result:** 
- 300 parameters in model have NO corresponding checkpoint weights
- These run with random initialization
- Random attention/LoRA corrupts the output

#### Issue 2: Grouped vs Full Convolutions
**Checkpoint:**
```python
conv1.weight: [512, 512, 3]  # Full connectivity: 512 in ‚Üí 512 out
```

**Model creates:**
```python
nn.Conv1d(512, 512, 3, groups=4)
# Creates shape: [512, 128, 3]  # Grouped: 512 in ‚Üí 512 out via 4 groups of 128
```

**Result:**
- Shape mismatch: `[512, 512, 3]` cannot load into `[512, 128, 3]`
- Even the basic conv1/conv2 weights fail to load
- Diagnostic shows 30 shape mismatches (lines 344-375)

#### Issue 3: Kernel Size vs Dilation
**Checkpoint approach:**
```python
convs.0: kernel_size=3, dilation=1  # Creates 3-sample receptive field
convs.1: kernel_size=5, dilation=1  # Creates 5-sample receptive field
convs.2: kernel_size=7, dilation=1  # Creates 7-sample receptive field
```

**Model approach:**
```python
convs.0: kernel_size=3, dilation=1  # Creates 3-sample receptive field
convs.1: kernel_size=3, dilation=3  # Creates 7-sample receptive field  
convs.2: kernel_size=3, dilation=5  # Creates 11-sample receptive field
```

**Result:**
- Different receptive field patterns
- Different weight dimensions for conv1/conv2
- Prevents weight loading even if shapes matched

### How This Causes Static Buzz

#### Step-by-Step Failure Mode:

1. **Model Initialization:**
   ```python
   # integrate_trained_model.py creates model
   model = TrainedModifiedHiFiGANGenerator()
   # Model has 394 parameters with random initialization
   ```

2. **Weight Loading Attempt:**
   ```python
   checkpoint = torch.load('best_model.pth')
   model.load_state_dict(checkpoint['model_state_dict'])
   
   # PyTorch tries to match keys:
   # ‚úì conv1.weight exists in both BUT shapes don't match!
   #   Checkpoint: [512, 512, 3]
   #   Model:      [512, 128, 3]  ‚Üê Can't load!
   # 
   # ‚úó channel_attention exists in model but NOT in checkpoint
   #   Model keeps random weights
   #
   # ‚úó lora_conv1 exists in model but NOT in checkpoint  
   #   Model keeps random weights
   #
   # Result: Most weights remain RANDOM!
   ```

3. **Audio Generation with Random Weights:**
   ```python
   # When vocoder runs:
   mel_input = [1, 80, 135]  # Input mel-spectrogram
   
   # Goes through random conv layers
   x = random_conv1(mel)  # Random output!
   x = random_attention(x)  # More randomness!
   x = random_lora(x)  # Even more random!
   audio_output = final_random_conv(x)  # Pure noise!
   ```

4. **Why It's White Noise:**
   - Random convolution kernels have no learned speech patterns
   - Cannot reconstruct harmonic structure from mel features
   - Output is uncorrelated random values at each time step
   - All frequencies get similar random treatment
   - **Result: Uniform spectral content = flat mel-spectrogram**

### Visual Evidence from Mel-Spectrogram

The mel-spectrogram comparison (`mel_comparison_full.png`) shows:

**Input (Spanish speech):**
```
Mel bins 1-80: ‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñà‚ñà‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà‚ñë‚ñë  ‚Üê Vertical variation
                ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë
                ‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë  ‚Üê Different patterns at different times
                ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë
                [Clear formant structure, harmonic patterns]
```

**Original Mode Output (Working vocoder):**
```
Mel bins 1-80: ‚ñë‚ñë‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñà‚ñà‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë  ‚Üê Vertical variation
                ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë
                ‚ñë‚ñë‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë  ‚Üê Speech patterns preserved
                ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë
                [Recognizable speech structure]
```

**Modified Mode Output (Random weights):**
```
Mel bins 1-80: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚Üê NO variation!
                ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚Üê All bins same value
                ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚Üê Completely flat
                ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚Üê White noise signature
                [No speech structure whatsoever]
```

The flat horizontal lines in the Modified output are the mathematical signature of white noise: when all frequency components have equal, uncorrelated random values at all time points, the mel-spectrogram shows uniform intensity across all bins, which is exactly what a vocoder with random weights produces.

---

## The Code Problem in Detail

### Location: `Important files - for tool/grc_lora.py`

The current `GroupedResidualConvolution` class (lines 56-150) creates this structure:

```python
class GroupedResidualConvolution(nn.Module):
    def __init__(self, channels, kernel_size=3, dilation=1, groups=4, lora_rank=4):
        super(GroupedResidualConvolution, self).__init__()
        
        # Problem 1: Grouped convolutions (checkpoint uses groups=1, full-channel)
        self.groups = max(1, min(groups, channels))  # groups=4
        
        # Problem 2: Creates grouped convs instead of full
        self.conv1 = nn.Conv1d(channels, channels, kernel_size, 
                              padding=(kernel_size-1)//2, dilation=dilation, 
                              groups=self.groups)  
        # This creates shape: [channels, channels/groups, kernel_size]
        # e.g., [512, 128, 3] instead of [512, 512, 3]
        
        self.conv2 = nn.Conv1d(channels, channels, kernel_size, 
                              padding=(kernel_size-1)//2, dilation=dilation, 
                              groups=self.groups)
        
        # Problem 3: Batch normalization NOT in checkpoint
        self.norm1 = nn.BatchNorm1d(channels)
        self.norm2 = nn.BatchNorm1d(channels)
        
        # Problem 4: LoRA adaptation NOT in checkpoint
        self.lora_conv1 = LoRALinear(channels, channels, rank=lora_rank)
        self.lora_conv2 = LoRALinear(channels, channels, rank=lora_rank)
        
        # Problem 5: Channel attention NOT in checkpoint
        self.channel_attention = nn.Sequential(
            nn.Conv1d(channels, channels // 4, 1),  # 2 more params
            nn.ReLU(),
            nn.Conv1d(channels // 4, channels, 1),  # 2 more params
            nn.Sigmoid()
        )
        
        # Problem 6: Temporal attention NOT in checkpoint
        self.temporal_attention = nn.Sequential(
            nn.Conv1d(1, 1, kernel_size, padding=(kernel_size-1)//2),  # 2 more params
            nn.Sigmoid()
        )
```

**This creates 24 parameters per GRC block, but checkpoint only has 4!**

### Location: `Important files - for tool/integrate_trained_model.py`

The model creation code (lines 70-102 after my attempted fix) tries to use this complex GRC:

```python
try:
    from grc_lora import GroupedResidualConvolution  # ‚Üê Wrong! Too complex
    
    class MultiReceptiveFieldFusion(nn.Module):
        def __init__(self, channels):
            super().__init__()
            # Creates 3 GRC blocks with dilation (WRONG approach)
            self.convs = nn.ModuleList([
                GroupedResidualConvolution(channels, kernel_size=3, dilation=1),
                GroupedResidualConvolution(channels, kernel_size=3, dilation=3),  # ‚Üê k=3, d=3
                GroupedResidualConvolution(channels, kernel_size=3, dilation=5)   # ‚Üê k=3, d=5
            ])
            # But checkpoint has:
            # convs.0: k=3, d=1
            # convs.1: k=5, d=1  ‚Üê Different kernel, not dilation!
            # convs.2: k=7, d=1
```

**This is why the fix I applied earlier didn't work** - I changed from `grc_lora_fixed` to `grc_lora`, but `grc_lora` itself is too complex!

---

## What Should Happen vs What Actually Happens

### Expected (If Weights Loaded Correctly):

```
Input mel ‚Üí 
  Conv1 (trained weights) ‚Üí 
  ReLU ‚Üí 
  Conv2 (trained weights) ‚Üí 
  Add residual ‚Üí 
Output audio (proper speech)

Mel-spectrogram: Clear vertical patterns (speech structure)
```

### Actual (With Random Weights):

```
Input mel ‚Üí 
  Conv1 (RANDOM weights) ‚Üí ReLU ‚Üí
  Norm1 (RANDOM weights) ‚Üí
  LoRA1 (RANDOM weights) ‚Üí
  Conv2 (RANDOM weights) ‚Üí
  Norm2 (RANDOM weights) ‚Üí
  LoRA2 (RANDOM weights) ‚Üí
  Channel Attention (RANDOM weights) ‚Üí
  Temporal Attention (RANDOM weights) ‚Üí
  Add residual ‚Üí
Output audio (white noise)

Mel-spectrogram: Flat horizontal lines (no structure)
```

---

## The Statistics Tell the Story

### From Diagnostic Output (Lines 311-316):

```
üìä KEY STATISTICS:
  Checkpoint keys: 94
  Model keys: 394        ‚Üê 4.2x more parameters!
  Common keys: 94        ‚Üê All checkpoint keys match names...
  Missing in model: 0
  Missing in checkpoint: 300  ‚Üê ...but 300 extra params in model!
```

### From Shape Mismatches (Lines 344-375):

```
‚ö†Ô∏è  SHAPE MISMATCHES (30):
  mrfs.0.convs.0.conv1.weight
    Checkpoint: [512, 512, 3]  ‚Üê Full channel
    Model:      [512, 128, 3]  ‚Üê Grouped (512/4=128)
  
  mrfs.1.convs.1.conv2.weight
    Checkpoint: [256, 256, 5]  ‚Üê kernel_size=5
    Model:      [256, 64, 3]   ‚Üê kernel_size=3, groups=4
  
  mrfs.2.convs.2.conv1.weight
    Checkpoint: [128, 128, 7]  ‚Üê kernel_size=7
    Model:      [128, 32, 3]   ‚Üê kernel_size=3, groups=4
```

**Every single conv1 and conv2 parameter has a shape mismatch!**

---

## Why This Explains Everything

### The Chipmunk ‚Üí Static Progression:

1. **Phase 1 (Chipmunk):**
   - Import errors prevented model initialization
   - System used fallback/passthrough audio
   - Sample rate mismatch on playback
   - **Audio was processed somewhere, just played wrong**

2. **Phase 2 (Static Buzz - Current):**
   - Imports fixed, model initializes
   - Architecture mismatch prevents weight loading
   - Vocoder runs with random weights
   - **Audio is generated by vocoder, but vocoder is untrained**

### Why Mel-Spectrogram is Flat:

Random neural network weights create **uncorrelated random mappings**:
```
mel[frequency=0, time=0] ‚Üí random_conv ‚Üí output[random_value_1]
mel[frequency=50, time=0] ‚Üí random_conv ‚Üí output[random_value_2]  
mel[frequency=80, time=0] ‚Üí random_conv ‚Üí output[random_value_3]

All random values have similar statistical properties (Gaussian)
‚Üí Similar magnitudes across all frequencies
‚Üí Flat mel-spectrogram
```

Trained weights create **learned harmonic mappings**:
```
mel[frequency=0, time=0] ‚Üí trained_conv ‚Üí output[harmonic_component_1]
mel[frequency=50, time=0] ‚Üí trained_conv ‚Üí output[formant_component_2]
mel[frequency=80, time=0] ‚Üí trained_conv ‚Üí output[high_freq_component_3]

Different frequencies ‚Üí different speech components
‚Üí Varying magnitudes across frequencies
‚Üí Patterned mel-spectrogram
```

---

## The Solution

### Create Simplified GRC (Already Done):

`grc_simple_matching_checkpoint.py`:
```python
class SimpleGRC(nn.Module):
    def __init__(self, channels, kernel_size=3, dilation=1):
        super().__init__()
        
        padding = (kernel_size - 1) // 2 * dilation
        
        # ONLY conv1 and conv2 - full channel (no grouping!)
        self.conv1 = nn.Conv1d(channels, channels, kernel_size,
                              padding=padding, dilation=dilation)
        
        self.conv2 = nn.Conv1d(channels, channels, kernel_size,
                              padding=padding, dilation=dilation)
    
    def forward(self, x):
        residual = x
        out = self.conv1(x)
        out = torch.relu(out)
        out = self.conv2(out)
        return out + residual

# Creates exactly 4 parameters: conv1.weight, conv1.bias, conv2.weight, conv2.bias
# Matches checkpoint structure perfectly!
```

### Update Model Loader (Already Done):

`integrate_trained_model.py` line 70:
```python
from grc_simple_matching_checkpoint import SimpleGRC

class MultiReceptiveFieldFusion(nn.Module):
    def __init__(self, channels):
        super().__init__()
        # Use varying kernel sizes (NOT dilations!)
        self.convs = nn.ModuleList([
            SimpleGRC(channels, kernel_size=3, dilation=1),
            SimpleGRC(channels, kernel_size=5, dilation=1),
            SimpleGRC(channels, kernel_size=7, dilation=1)
        ])
```

### Expected Results After Fix:

**Architecture diagnostic should show:**
```
Checkpoint keys: 94
Model keys: 94        ‚Üê Should match!
Common keys: 94
Missing in model: 0
Missing in checkpoint: 0  ‚Üê Should be 0!
Shape mismatches: 0       ‚Üê Should be 0!
```

**Audio diagnostic should show:**
```
Modified mode mel-spectrogram: Clear vertical variations ‚úÖ
Modified mode audio: Proper speech ‚úÖ
No static buzz ‚úÖ
```

---

## Conclusion

The diagnostic output definitively proves that the static buzz is not a sample rate issue, not a preprocessing issue, and not a post-processing issue, but rather a **fundamental vocoder failure** caused by attempting to run a complex neural network (394 parameters with attention, LoRA, and normalization layers) using a simple checkpoint (94 parameters with only basic convolutions), where the architectural incompatibility prevents weight loading, forcing the vocoder to operate with random uninitialized weights that generate white noise instead of reconstructing speech from mel-spectrograms, manifesting visually as perfectly flat horizontal lines across all 80 mel-frequency bins (indicating uniform spectral content with zero structure) and audibly as static buzzing (white noise). The fix requires replacing the complex `GroupedResidualConvolution` implementation with a simplified version (`SimpleGRC`) that matches the checkpoint's actual structure: 4 parameters per block (conv1.weight, conv1.bias, conv2.weight, conv2.bias), full-channel convolutions without grouping (shapes like `[512, 512, 3]` instead of `[512, 128, 3]`), and varying kernel sizes (3, 5, 7) instead of fixed kernel size with varying dilations, which will allow the 94 trained parameters to load correctly and enable the vocoder to generate proper speech with vertical mel-spectrogram variations instead of white noise with flat spectral signatures.

