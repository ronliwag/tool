# Training Configuration for Modified HiFi-GAN with Expressive Voice Cloning
# Dataset paths point to external directory: D:\Thesis Tool - Datasets\

# Dataset Configuration
datasets:
  # External dataset directory (separate from main project)
  external_data_dir: "E:/Thesis_Datasets"
  
  # CVSS-T Dataset (Primary dataset for training)
  cvss_t:
    path: "E:/Thesis_Datasets/CommonVoice_v4/es/cv-corpus-22.0-2025-06-20/es/2nd Batch - 5000"
    languages: ["en", "es"]  # English and Spanish
    directions: ["en-es", "es-en"]
    sample_rate: 16000
  
  # Additional datasets
  additional:
    en_tar: "E:/Thesis_Datasets/CommonVoice_v4/en.tar"  # 39GB English dataset
    es_tar: "E:/Thesis_Datasets/CommonVoice_v4/es.tar"  # 47GB Spanish dataset
    validation_split: 0.1
    test_split: 0.1

# Model Configuration
models:
  # HiFi-GAN Modified (Your contribution)
  hifigan_modified:
    mel_channels: 80
    speaker_embedding_dim: 192  # ECAPA-TDNN output
    emotion_embedding_dim: 384  # Emotion2Vec output
    hidden_size: 512
    num_layers: 3
    dropout: 0.1
    
  # HiFi-GAN Baseline (for comparison)
  hifigan_baseline:
    mel_channels: 80
    hidden_size: 512
    num_layers: 3
    dropout: 0.1
    
  # Speaker Encoder (ECAPA-TDNN)
  speaker_encoder:
    model_name: "speechbrain/spkrec-ecapa-voxceleb"
    embedding_dim: 192
    
  # Emotion Encoder (Emotion2Vec)
  emotion_encoder:
    model_name: "facebook/wav2vec2-base"
    hidden_size: 768
    num_emotions: 8
    embedding_dim: 384

# Training Configuration
training:
  # General settings
  batch_size: 16
  learning_rate: 2e-4
  num_epochs: 1000
  warmup_steps: 2000
  save_steps: 5000
  eval_steps: 2500
  gradient_accumulation_steps: 2
  log_interval: 100
  lr_scheduler_step: 1000
  lr_scheduler_gamma: 0.9
  
  # Optimizer
  optimizer: "adam"
  weight_decay: 1e-4
  beta1: 0.8
  beta2: 0.99
  
  # Learning rate scheduler
  scheduler: "cosine"
  min_lr: 1e-6
  
  # Output directory for checkpoints
  output_dir: "checkpoints"
  
  # Loss weights
  losses:
    mel_loss_weight: 1.0
    feature_loss_weight: 1.0
    speaker_loss_weight: 0.1
    emotion_loss_weight: 0.1
    
  # Data augmentation
  augmentation:
    pitch_shift: [-2, 2]  # semitones
    time_stretch: [0.9, 1.1]
    noise_level: 0.01

# Evaluation Configuration
evaluation:
  # Metrics
  metrics:
    sim_threshold: 0.7
    bleu_n_gram: 4
    lagging_window: 1000  # ms
    
  # Evaluation frequency
  eval_frequency: 1000  # steps
  
  # Test set
  test_data_dir: "E:/Thesis_Datasets/CVSS-T/test"

# Output Configuration
output:
  # Model checkpoints
  model_dir: "models/trained"
  checkpoint_dir: "training/checkpoints"
  
  # Logs
  log_dir: "training/logs"
  tensorboard_dir: "training/tensorboard"
  
  # Results
  results_dir: "evaluation/results"
  
  # Generated audio samples
  samples_dir: "evaluation/samples"

# Hardware Configuration
hardware:
  device: "cuda"  # or "cpu"
  num_workers: 4
  pin_memory: true
  
# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "training/training.log"

# Experiment Configuration
experiment:
  name: "modified_hifigan_expressive_cloning"
  description: "Modified HiFi-GAN with ODConv, GRC+LoRA, and FiLM conditioning for expressive voice cloning"
  tags: ["hifigan", "vocoder", "voice_cloning", "emotion", "streamspeech"]
